# LinkReview

- Here we collect all the works that may be useful for writing our paper
- We divide these works by topic in order to structure them

> [!NOTE]
> This review table will be updated, so it is not a final version.

| Topic | Title | Year | Authors | Paper | Code | Summary |
| :--- | :--- | :---: | :--- | :---: | :---: | :--- |
| Key Article 1 | Unraveling the Hessian: A Key to Smooth Convergence in Loss Function Landscapes | 2024 | Nikita Kiselev, Andrey Grabovoy | [arXiv](https://arxiv.org/abs/2409.11995) | [github](https://github.com/kisnikser/landscape-hessian) | Upper bounds via Hessian for fully connected neural networks |
| Key Article 2 | ConvNets Landscape Convergence: Hessian-Based Analysis of Matricized Networks | 2024 | Vladislav Meshkov, Nikita Kiselev, Andrey Grabovoy | IN PUBLISHING | IN PUBLISHING | Upper bounds via Hessian for convolutional neural networks |
| Key Article 3 | Empirical Analysis of the Hessian of Over-Parametrized Neural Networks | 2018 | Levent Sagun, Utku Evci, Ugur Guney, Yann Dauphin, Leon Bottou | [arXiv](https://arxiv.org/pdf/1706.04454) | --- | In overtrained neural networks the Hessian rank is often low, and in fact the active subspace, which affects the overall shape of the loss landscape, may be significantly smaller. |
| Supporting Article 1 | Visualizing the Loss Landscape of Neural Nets | 2018 | Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, Tom Goldstein | [arXiv](https://arxiv.org/pdf/1712.09913) | --- | Methods of visualizing loss function curvature and applying a comparizon between different functions |
| Supporting Article 2 | An Investigation into Neural Net Optimization via Hessian Eigenvalue Density | 2019 | Behrooz Ghorbani, Shankar Krishnan, Ying Xiao | [proceedings](https://proceedings.mlr.press/v97/ghorbani19b/ghorbani19b.pdf) | --- | Observed the rapid appearance of large isolated eigenvalues in the spectrum, along with a surprising concentration of the gradient in the corresponding eigenspaces. |
| Experiment base | Training Compute-Optimal Large Language Models | 2022 | Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, Laurent Sifre | [arXiv](https://arxiv.org/abs/2203.15556) | --- | The idea of overloaded models and the reason of importance optimal training size estimation |
| Technical literature | The Matrix Cookbook | 2012 | Kaare Petersen, Michael Pedersen | [pdf](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) | --- | A collection of facts about matrices and matters relating to them |
| Dataset 1 | The mnist database of handwritten digit images for machine learning research | 2012 | L. Deng | [pdf](https://api.semanticscholar.org/CorpusID:5280072) | [link](https://www.kaggle.com/datasets/hojjatk/mnist-dataset) | The database of handwritten digits. |
| Dataset 2 | Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms | 2017 | H. Xiao, K. Rasul, and R. Vollgraf | [arXiv](http://arxiv.org/abs/1708.07747) | [github](https://github.com/zalandoresearch/fashion-mnist) | A dataset of Zalando's article images |
